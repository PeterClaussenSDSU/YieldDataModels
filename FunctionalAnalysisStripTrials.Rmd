---
title: "Functional Data Analysis and Experimental Design for On-farm Strip Trials"
author: "Peter Claussen"
date: "10/13/2021"
output:
  html_document: default
  pdf_document: default
bibliography: biblio.bib
---

<!-- See ASA_CSSA_SSSA/2018/ThoughtsAboutPower -->

```{r,echo=FALSE}
library(splines)
library(ggplot2)
library(gridExtra)
library(mgcv)

cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#0072B2", "#D55E00", "#F0E442","#CC79A7","#000000","#734f80", "#2b5a74", "#004f39", "#787221", "#003959", "#6aaf00", "#663cd3")
grey <- cbPalette[1] #"#999999"
orange <- cbPalette[2] #"#E69F00"
skyblue <- cbPalette[3] #"#56B4E9"
bluishgreen <- cbPalette[4] #"#009E73"
yellow <- cbPalette[7] #"#F0E442"
blue <- cbPalette[5] #"#0072B2"
vermillion <- cbPalette[6] #"#D55E00"
pair.colors <- c(2,5)
```
# Introduction

Collaborative research between agronomists and farmers has a long history, but recent technological 
advances has greatly increased opportunities for on-farm research. For our purposes, we will define 
on-farm research as comparative experiments 1) conducted on farmer-owned fields, 2) treatments applied 
using farmer-owned equipment and 3) data collected using farmer-owned harvesters. 3) implies the use 
of GPS-enabled yield data monitors, while 2) and 3) determine the nature of experimental units. 
Specifically, the dimensions of the experimental units will be determined by the width of farm implements 
and by the length of a typical planting, application or harvest pass.

We will consider a ‘pass’ as a simple complete farming operation, e.g. the interval between when a planter 
is lowered into the soil at one end of the field to when the planter is raised at the other end of the field. 
As such, each pass may be thought of in terms of a traditional plot, albeit a very long and very thin plot. 
However, a very long and very thin rectangle becomes increasingly similar to a single line, and we can easily 
model yield as function of position on this line. Thus, the analysis of yield monitor data is a likely candidate 
for functional data analysis.

## Univariate Data Analysis

To introduce functional data analysis, we start with a simple strip trial for variety testing. We will show 
how a simple univariate analysis - independent means t-test - is extended to an analysis of functional data.



We will further simplify the analysis by modeling the experiment as an a comparison of two means with pooled 
standard deviation, using a simple t-test. Write the statistical model as

$$
y_{ij} = \mu_i + e_{ij}
$$

Let

$$
t = \frac{\widehat{\delta}}{\sqrt{2 \widehat{\sigma}^2 / n}}
$$
where

$$
\begin{aligned}
\widehat{\mu}_i & = \frac{\sum_{j=1}^{N_i} y_{ij}}{N_i} \\
\widehat{\sigma}^2 & = \frac{\sum_{j=1}^{N} (y_{ij}-\widehat{\mu}_i)^2}{N - k} \\
\widehat{\delta} & = \widehat{\mu}_i-\widehat{\mu}_j
\end{aligned}
$$

Then for this example (Table 1), t = 2.35 and p(t)=0.04.

## Functional Data Analysis
To extend the univariate analysis to a functional analysis, we first need to model the experimental unit as a function over some variable; preferably a variable that allows us to compare equivalent subsamples from each unit. In this case, we want to compare different strips at equivalent positions in the field; in other cases, we may wish to compare measurements made at equivalent time intervals or growth stages.

$$
y_{ij}(d) = \text{Yield at distance } d
$$
when the field is approximately rectangular and distance can be measured from a fixed side (i.e. the eastern edge of the harvest area).

Then each formula from # has a functional equivalent (Table 2). Letting a line running perpendicular to the main axis of the strips, at one side of the field, represent the origin, (#) provides an estimate of yield at any distance d from the origin.  

## Functional Forms for Functional Data
Consider each strip as an independent experimental unit, denoted $Y_i$. Where it is necessary to discuss multiple strips in the same context, we will use $Y_1, \dots, Y_k$ to denote $k$ strips. Further, we will denote a specific observation from strip $Y_i$ at the distance $d$ as $Y_i(d)$, thus denoting the specific observation as a function of distance.

In general, $Y(d)$ will take a functional form, with as associated measurement error

$$
Y_i(d) = \mathbf{A_i}{\mathbf{\theta}} + f_i(d) + \mathbf{e}(d)
$$

Choosing an appropriate function $f$ is part of the art of functional analysis. The choice of function is largely going to depend on the relative importance placed on two components of the functional form - smoothing and interpolation.

Functional data are in theory continuous values, but data are commonly collected at discrete intervals, and measurement errors occur during when functions are sampled. Smoothing occurs when functional forms are chosen to minimize variance between the function values at sample points and the sampled values.

Discrete functional data units are frequently cannot be sampled at identical independent values (i.d. the same $d$). Instead, values at non-sampled d are inferred from sample points $Y(d)$ by a process of interpolation. The number of sampled points used for each interpolated value characterizes the choice of functional forms.


A generalized additive model following from our previous examples may take the form (adapted from )

$$
g(y_i) = \mathbf{A_i} \mathbf{\theta} + f(x_{1i}) +f(x_{2i},x_{3i}) + e_i
$$
where $\mathbf{A_i} \mathbf{\theta}$ are the strictly parametric components of the model and  $f(\circ)$ is a function form of the covariate $x_1, \dots $. In the functional analysis of strip trials, $\mathbf{A_i} \mathbf{\theta}$ would represent the treatment structure while $f(x_{1i})$ represents a smooth function of yield over distance.

In this case, we can assume $g(y_i)=y_i$ and $\mathbf{A_i} \mathbf{\theta} = \mu_i$, so this simplifies to a linear model with respect to the smoothing function. We will use distance from the west end of the field as covariate $\delta = x_1$

$$
y_i = f(\delta) + e_i
$$

## Forms of $f(\delta)$

The choice of $f(\delta)$ depends largely on a smoothing parameter $\lambda$ that determines how 'smooth' or 'wiggly' the resulting interpolating function fits the data. Too smooth and the data are underfit, loosing information, but too wiggly and the data are overfit, including too much error variance in the model. We use the R library `mgcv` to perform generalized cross-validation (Generalized Additive Models, p 169) of the fitted function $f(\delta)$ to obtain an appropriately smooth $f(\delta)$. Fitted values are then taken as the true yield at point $\delta$, and this value is used to compute summary statistics for functional data analysis.

<!-- ## Extension to Power Analysis -->

<!-- Once a statistical test has been determined, historical or expected values for treatment effect size and variance terms can be used to plan for future analysis. Briefly, start with the t statistic. Assuming  effect size d and and standard deviation s, the t ratio can be re-arranged to solve for the number of replicates required to meet or exceed a desired critical t value. -->

<!-- $$ -->
<!-- n \ge \left( \frac{2 \sigma^2}{\delta} \right)^2 t_{\alpha,\nu} -->
<!-- $$ -->


<!-- Additionally, when planning trials, and second critical value is included to protect against type II errors.  -->

<!-- $$ -->
<!-- n \ge \left( \frac{2 \sigma^2}{\delta} \right)^2 (t_{\alpha,\nu} - t_{\beta,\nu, ncp})^2 -->
<!-- $$ -->

<!-- Similarly, a detectable treatment effect size can be calculated from -->

<!-- $$ -->
<!-- \delta = \frac{2 \sigma^2 (t_{\alpha} - t_{\beta})}{\sqrt{n}} -->
<!-- $$ -->

<!-- Frequently, the number of required replicates will be calculated for a range of effect sizes, and effect size will be calculated for a range of practical replicates. These formula have functional forms that follow from the functional t statistic (Table #) -->


## Functional Omnibus Test

Suppose we wish to have an omnibus test of significance for treatment effect, independent of position - that is, a main treatment effect as opposed to a treatment by position interaction effect. The traditional analysis of variance would test the mean squares of treatment means over strips against residual error. 

# Materials and Methods

## Example 1

In this experiment, two varieties were tested using a split-planter comparison method [@doerge-07-1999].
Two varieties were assigned to the left and to they right half of a standard corn planter. Seed was harvested 
with a GSP enabled combined, with the width of the harvester one-half the planter width. Twelve passes 
were planted, representing two planted strips, and 24 passes were harvested. The length of each harvest pass was approximately 400m. Portions of the harvest and yield maps are shown in Figure #.

Each harvest pass was smoothed in R using the `gam` function from the `mgcv` library by first fitting yield values to distance from the west edge of the field, using code of the form `gam(Yield ~ s(Easting),...)`. The fitted model was used to predict yield on a common distance basis of values from 2 to 398 (Figure #). Since each harvest pass represents half of a planter pass, two harvest passes were merged by taking the average of the two passes at each distance point to form a single strip (Figure #). This provided 12 experimental units with two treatments and six replicates for functional data analysis.

It should be noted that this is a simplification of the design. 



From Table #, the functional t-test follows as illustrated in Figure #. Briefly, for each distance value in the common distance basis (${2,4,\dots, 398}$) means, standard deviations, $t$-statistics and $p$-values were computed and plotted (Figure #).

# Example 2

The second example is a fungicide trial where the farmer was instructed to spray a fungicidal treatment in alternating strips in a field of his choosing; the number and location of strips was also chosen by the farmer. In this case, the farmer started spraying at the gate leading into the field and moved to the east with each spray pass. The sprayer boom covered the width of four harvest passes, so each treated strip consisted of four harvest pass samples. Spray and harvest maps are show in Figure #.

The field contained several incipent wetlands that could not be planted; instead buffer rows were planted and harvested around each wetland (as shown by gaps in the yield map). Harvest values from these buffer rows were included in the yield associated with harvest strips, but may introduce error in yield estimates for some locations in the strips.

gam smoothing models were fit to yield values for each harvest pass (Figure #), then the predicted values for each harvest pass were averaged to provide an estimate of yield for each treated strip (Figure #). The field was not a uniform rectangle, so some treated strips are longer than others. 

Treatment differences, standard deviations, t-statistics and p-values were calculated as described in the previous section, with the exception that the number of strips was also computed at each distance. The distance basis was measured from the south end of the field.

# Results

## Example 1
As shown in Figure #, the difference between treatment means is presented a continuous function of distance $d$ from the western edge of the field. In this example the difference is greatest in the eastern half of the field. Standard deviation also varies with position, but is greater in the western part of the field. Since $t$ is a function of both difference and standard deviation (in this example, replicates are constant across the field) the test of significance also varies with position and the p-value associated with this test is more often significant in the western part of the field.

We should note that the largest region of significant differences between varieties occurs in a higher yield part of the field; the differences in low fertility zones are smaller and not statistically significant. This provides information about the physical cause of varietal differences. We might infer from this that variety # is a superior performer in high-yield zones, but still performs well in low-yield zones.

## Example 2



```{r,echo=FALSE}
load(file="~/Work/git/ASA_CSSA_SSSA/2017/Workshop/Case Study 2/Strips.Rda")
```

```{r,echo=FALSE}
EastQuarter.dat$Pass <- floor(EastQuarter.dat$Northing/6)+1
EastQuarter.dat$Pair <- floor((EastQuarter.dat$Pass+1)/2)
EastQuarter.dat$Direction <- "Easterly"
EastQuarter.dat$Direction[EastQuarter.dat$Heading>100] <- "Westerly"
EastQuarter.dat$Direction <- as.factor(EastQuarter.dat$Direction)

#EastQuarter.dat$Pass[EastQuarter.dat$Heading>100] <- EastQuarter.dat$Pass[EastQuarter.dat$Heading>100] + 400
EastQuarter.dat$PassNo <- EastQuarter.dat$Pass

EastQuarter.dat$Block <- ceiling(EastQuarter.dat$Pair/2)
EastQuarter.dat$Strip <- EastQuarter.dat$Pair %/% EastQuarter.dat$Block
EastQuarter.dat$Block <- as.factor(EastQuarter.dat$Block)
EastQuarter.dat$Pass <- as.factor(EastQuarter.dat$Pass)
EastQuarter.dat$Pair <- as.factor(EastQuarter.dat$Pair)
EastQuarter.dat$Strip <- as.factor(EastQuarter.dat$Strip)
```

```{r,eval=FALSE}
ggplot(EastQuarter.dat, aes(Easting,Northing)) + 
           geom_point(aes(colour = Block),size=2) + 
           scale_colour_manual(values=cbPalette) +
           labs(colour = "Block", x="Easting", y="Northing", title = "Seeding Map")
```


```{r,EastQuarterMaps,echo=FALSE,fig.width=8,fig.height=6}
grid.arrange(
  arrangeGrob(
        ggplot(EastQuarter.dat, aes(Easting,Northing)) + 
           geom_point(aes(colour = Product),size=2) + 
           scale_colour_manual(values=cbPalette[pair.colors]) +
           labs(colour = "Variety", x="Easting", y="Northing", title = "Seeding Map"),
    ggplot(EastQuarter.dat, aes(Easting,Northing)) + 
           geom_point(aes(colour = Yield),size=2) + 
           scale_colour_gradient2(low=vermillion, mid=yellow, high=blue, midpoint = median(EastQuarter.dat$Yield)) +
           labs(colour = "Yield", x="Easting", y="Northing",title="Harvest Map"),
    nrow=2
  )
)
```

```{r,echo=FALSE,include=FALSE}
means.dat <- with(EastQuarter.dat, data.frame(
  Pass = aggregate(Yield ~ Pair,EastQuarter.dat,mean,na.rm=TRUE)[,1],
  Yield = aggregate(Yield ~ Pair,EastQuarter.dat,mean,na.rm=TRUE)[,2],
  Product = aggregate(as.numeric(Product) ~ Pair,EastQuarter.dat,mean,na.rm=TRUE)[,2],
  Northing = aggregate(Northing ~ Pair,EastQuarter.dat,mean,na.rm=TRUE)[,2]
))
means.dat
means.dat$Product <- levels(EastQuarter.dat$Product)[means.dat$Product]
```


```{r,echo=FALSE,fig.width=8,fig.height=3}
ggplot(means.dat, aes(x=Northing, y=Yield, color=Product,fill=Product)) +
  geom_bar(stat="identity") + scale_colour_manual(values=cbPalette[pair.colors]) + scale_fill_manual(values=cbPalette[pair.colors])
```



```{r,echo=FALSE}
smooth.basis <- rep(seq(2,398,by=2))
total.passes <- max(EastQuarter.dat$PassNo)
Smoothed.dat <- data.frame(
  Yield = rep(0,total.passes*length(smooth.basis)),
  Easting = rep(smooth.basis,total.passes),
  PassNo = rep(1:total.passes,each=length(smooth.basis)),
  Pair = rep(0,total.passes*length(smooth.basis)),
  Product = rep(levels(EastQuarter.dat$Product),total.passes*length(smooth.basis)/2),
  Northing = rep(0,total.passes*length(smooth.basis))
)
for(i in 1:total.passes) {
  current.pass <- EastQuarter.dat[EastQuarter.dat$PassNo==i,]
  #current.loess <- loess(Yield ~ Easting,data=current.pass)
  current.gam <- gam(Yield ~ s(Easting),data=current.pass)
  #current.smoothed <- predict(current.loess, data.frame(Easting = smooth.basis))
  current.smoothed <- predict(current.gam, data.frame(Easting = smooth.basis))
  Smoothed.dat$Yield[Smoothed.dat$PassNo==i] <- current.smoothed
  Smoothed.dat$Pair[Smoothed.dat$PassNo==i] <- current.pass$Pair[1]
  Smoothed.dat$Product[Smoothed.dat$PassNo==i] <- as.character(current.pass$Product[1])
  Smoothed.dat$Northing[Smoothed.dat$PassNo==i] <- mean(current.pass$Northing)
}
Smoothed.dat$Pass <- as.factor(Smoothed.dat$PassNo)
Smoothed.dat$Product <- as.factor(Smoothed.dat$Product)
#Smoothed.dat$Product <- levels(EastQuarter.dat$Product)[Smoothed.dat$Product]
```

```{r,echo=FALSE}
Aggregated.dat <- aggregate(Yield ~ Easting + Product + Pair,FUN=mean, data=Smoothed.dat)
#Aggregated.dat$Product <- levels(EastQuarter.dat$Product)[Aggregated.dat$Product]
```

```{r}
EQpooled.dat <- EastQuarter.dat[,c('Easting','Yield','Product')]
EQpooled.dat$Source <- 'As Harvested'
Smoothed.dat$Source <- 'GAM Predicted by Harvest Pass'
EQpooled.dat <- rbind(EQpooled.dat,Smoothed.dat[c('Easting','Yield','Product','Source')])
Aggregated.dat$Source <- 'Yield aggregated by strip'
EQpooled.dat <- rbind(EQpooled.dat,Aggregated.dat[c('Easting','Yield','Product','Source')])
```

```{r,ECombinedVarietyPlot,echo=FALSE,fig.width=8,fig.height=9}
ggplot(EQpooled.dat, aes(Easting,Yield)) + 
geom_point(aes(colour = Product),size=.2) + 
scale_colour_manual(values=cbPalette[pair.colors]) + 
#scale_colour_manual(values=cbPalette) + 
labs(colour = "Variety", x="Easting", y="Yield", title = "Variety Trial, Smoothing and Aggregating Strips") +
  ylim(100, 240) + facet_wrap(~Source,nrow = 3)
```


```{r,EastQuarterActualYield,eval=FALSE,echo=FALSE,fig.width=8,fig.height=3}
ggplot(EastQuarter.dat, aes(Easting,Yield)) + 
geom_point(aes(colour = Product),size=.2) + 
scale_colour_manual(values=cbPalette[pair.colors]) + 
labs(colour = "Variety", x="Easting", y="Yield", title = "East Quarter, as Harvested") +
  ylim(100, 240)
```

```{r,EastQuarterHarvestPasses,eval=FALSE,echo=FALSE,fig.width=8,fig.height=3}
ggplot(Smoothed.dat, aes(Easting,Yield)) + 
geom_point(aes(colour = Product),size=.2) + 
scale_colour_manual(values=cbPalette[pair.colors]) + 
labs(colour = "Variety", x="Easting", y="Yield", title = "East Quarter, Smoothed Strips") +
  ylim(100, 240)
```

```{r,EastQuarterAnalyzedPasses,eval=FALSE,echo=FALSE,fig.width=8,fig.height=3}
ggplot(Aggregated.dat, aes(Easting,Yield)) + 
geom_point(aes(colour = Product),size=.2) + 
scale_colour_manual(values=cbPalette[pair.colors]) + 
labs(colour = "Variety", x="Easting", y="Yield", title = "East Quarter, Pooled Strips") +
  ylim(100, 240)
```


```{r,echo=FALSE}
TTests <- data.frame(
  Easting = smooth.basis
)
for(i in 1:length(smooth.basis)) {
  l <- smooth.basis[i]
  obs <- Aggregated.dat[Aggregated.dat$Easting==l,]
  product.means <- tapply(obs$Yield,list(obs$Product),mean,na.rm=TRUE)
  product.sd <- tapply(obs$Yield,list(obs$Product),sd,na.rm=TRUE)
  TTests$Delta[i] <- product.means[1]-product.means[2]
  TTests$SD[i] <- sqrt(sum(product.sd^2)/2)
}
TTests$t <- TTests$Delta/(sqrt((2*TTests$SD^2)/6))
TTests$P <- 2*(1-pt(TTests$t,10))
```


```{r,echo=FALSE,fig.width=8,fig.height=6}
CombinedT <- data.frame(
  Easting=rep(TTests$Easting,4),
  Measure = c(rep('Treatment Differences',length(TTests$Delta)),
              rep('Standard Deviation',length(TTests$SD)),
              rep('t Ratio',length(TTests$t)),
              rep('Probability>t',length(TTests$P))),
  Value = c(TTests$Delta,TTests$SD,TTests$t,TTests$P),
  Signficant = rep(TTests$P<0.05,4)
)
CombinedT$Measure <- factor(CombinedT$Measure,levels=c('Treatment Differences','Standard Deviation','t Ratio','Probability>t'))
ggplot(CombinedT, aes(Easting,Value)) + 
geom_point(aes(color=Signficant)) + #cbPalette[1]) + 
scale_colour_manual(values=cbPalette) +
labs(x="Easting", title = "Functional Statistics") + facet_wrap(~ Measure,nrow = 4,scales="free_y")
```



```{r,eval=FALSE}
EastQuarter.gam <- gam(Yield ~ Product + s(Easting),data=EastQuarter.dat)
```


## Example 2

```{r,echo=FALSE}
treated.2019.dat <- read.csv(file='../ManagementZoneML/data/B 2019 Soybeans Treated.csv')
left = 1000
treated.2019.dat <- treated.2019.dat[treated.2019.dat$Longitude >left,]
```


```{r,echo=FALSE}
treated.2019.dat$Pass <- treated.2019.dat$Block
treated.2019.dat$Block <- as.factor(ceiling(treated.2019.dat$Pass/2))
treated.2019.dat$Sprayed <- treated.2019.dat$Pass %in% c(2,4,6,8)
treated.2019.dat$Strip <- factor(treated.2019.dat$Pass):factor(treated.2019.dat$Sample)
```

```{r,eval=FALSE}
ggplot(treated.2019.dat, aes(Longitude,Latitude)) + 
geom_point(aes(colour = Sample),size=1) + 
scale_colour_gradient2(low=vermillion, mid=yellow, high=blue, midpoint = 0.5) +
labs(colour = "Relative Rank", x="Easting", y="Northing", title = "Strip Trial")
```

```{r,echo=FALSE,fig.width=10,fig.height=6}
treated.2019.dat$SprayedRank <- rank(treated.2019.dat$Sprayed)
treated.2019.dat$SprayedRank <- treated.2019.dat$SprayedRank/max(treated.2019.dat$SprayedRank)

treated.2019.dat$YieldRank <- rank(treated.2019.dat$Yield)
treated.2019.dat$YieldRank <- treated.2019.dat$YieldRank/max(treated.2019.dat$YieldRank)

MapsSprayed <- data.frame(Longitude=c(treated.2019.dat$Longitude,
                                treated.2019.dat$Longitude),
                   Latitude=c(treated.2019.dat$Latitude,
                              treated.2019.dat$Latitude),
                   Value=c(treated.2019.dat$SprayedRank,
                           treated.2019.dat$YieldRank),
                   Map=c(rep('Spray',length(treated.2019.dat$SprayedRank)),
                         rep('Yield',length(treated.2019.dat$YieldRank))))
ggplot(MapsSprayed, aes(Longitude,Latitude)) + 
geom_point(aes(colour = Value),size=1) + 
scale_colour_gradient2(low=vermillion, mid=yellow, high=blue, midpoint = 0.5) +
labs(colour = "Relative Rank", x="Easting", y="Northing", title = "Strip Trial") + facet_wrap(~ Map)
```


```{r,echo=FALSE}
#remove most of the field, passes and samples were manually added in QGIS
treated.2019.dat <- treated.2019.dat[treated.2019.dat$Pass !=0,]
treated.2019.dat <- treated.2019.dat[treated.2019.dat$Sample !=0,]
strips <- unique(treated.2019.dat$Strip)
treated.2019.dat$Northing <- treated.2019.dat$Latitude
treated.2019.dat$Easting <- treated.2019.dat$Longitude
```

```{r,FungicideActualYield,echo=FALSE,fig.width=8,fig.height=3}
ggplot(treated.2019.dat, aes(Northing,Yield)) + 
geom_point(aes(colour = Sprayed),size=.2) + 
scale_colour_manual(values=cbPalette[pair.colors]) + 
labs(colour = "Sprayed", x="Northing", y="Yield", title = "Fungicide Trial, as Harvested") + ylim(0,60)
```

```{r, echo=FALSE}
Yield2 = NULL
Easting2 = NULL
Strip2 = NULL
Block2 = NULL
Treated2 = NULL
Northing2 = NULL
Pass2 <- NULL

for(strip in strips) {
  current.strip <- treated.2019.dat[treated.2019.dat$Strip==strip,]
  MinN <- ceiling(min(current.strip$Northing))
  MaxN <- floor(max(current.strip$Northing))
  #may not be an even integer
  MinN <- 2*(ceiling(MinN/2))
  MaxN <- 2*(ceiling(MaxN/2))
  smooth2.basis <- seq(MinN,MaxN,by=2)
  current.gam <- gam(Yield ~ s(Northing),data=current.strip)
  current.smoothed <- predict(current.gam, data.frame(Northing = smooth2.basis))
  L <- length(current.smoothed)
  Yield2 <- c(Yield2,current.smoothed)
  Easting2 <- c(Easting2,rep(mean(current.strip$Easting),L))
  Strip2 <- c(Strip2,rep(strip,L))
  Block2 <- c(Block2,rep(current.strip$Block[1],L))
  Pass2 <- c(Pass2,rep(current.strip$Pass[1],L))
  Treated2 <- c(Treated2,rep(current.strip$Sprayed[1],L))
  Northing2 <- c(Northing2,smooth2.basis)
}


Smoothed2.dat <- data.frame(
  Yield = Yield2,
  Easting = Easting2,
  Strip = Strip2,
  Block = Block2,
  Pass = Pass2,
  Treated = Treated2,
  Northing = Northing2
)
```

```{r,AndersonsHarvestStrips,echo=FALSE,fig.width=8,fig.height=3}
ggplot(Smoothed2.dat, aes(Northing,Yield)) + 
geom_point(aes(colour = Treated),size=.2) +
scale_colour_manual(values=cbPalette[pair.colors]) + 
labs(colour = "Sprayed", x="Northing", y="Yield", title = "Fungicide Trial, Smoothed Strips")
```

```{r}
Aggregated2.dat <- aggregate(Yield ~ Northing + Pass, FUN=mean, data=Smoothed2.dat)
Aggregated2.dat$Treated <- Aggregated2.dat$Pass %in% c(2,4,6,8)
```

```{r,FungicideAnalyzedPasses,echo=FALSE,fig.width=8,fig.height=3}
ggplot(Aggregated2.dat, aes(Northing,Yield)) + 
geom_point(aes(colour = Treated),size=.2) + 
scale_colour_manual(values=cbPalette[pair.colors]) + 
labs(colour = "Variety", x="Northing", y="Yield", title = "Fungicide, Pooled Strips")
```

```{r,echo=FALSE}
MinN <- min(Aggregated2.dat$Northing)
MaxN <- max(Aggregated2.dat$Northing)
t.basis <- seq(MinN,MaxN,by=2)
TTests2 <- data.frame(
  Northing = t.basis
)
for(i in 1:length(t.basis)) {
  l <- t.basis[i]
  obs <- Aggregated2.dat[Aggregated2.dat$Northing==l,]
  product.means <- tapply(obs$Yield,list(obs$Treated),mean,na.rm=TRUE)
  product.sd <- tapply(obs$Yield,list(obs$Treated),sd,na.rm=TRUE)
  TTests2$Delta[i] <- product.means[2]-product.means[1] #since FALSE is ordered first
  TTests2$SD[i] <- sqrt(sum(product.sd^2)/2)
  TTests2$n[i] <- length(obs)/2
}
TTests2$t <- abs(TTests2$Delta/(sqrt((2*TTests2$SD^2)/TTests2$n)))
TTests2$P <- 2*(1-pt(TTests2$t,2*(TTests2$n-1)))
```


```{r,echo=FALSE,fig.width=8,fig.height=6}
CombinedT2 <- data.frame(
  Northing=rep(TTests2$Northing,4),
  Measure = c(rep('Treatment Differences',length(TTests2$Delta)),
              rep('Standard Deviation',length(TTests2$SD)),
              rep('t Ratio',length(TTests2$t)),
              rep('Probability>t',length(TTests2$P))),
  Value = c(TTests2$Delta,TTests2$SD,TTests2$t,TTests2$P),
  Signficant = rep(TTests2$P<0.05,4)
)

CombinedT2 <- CombinedT2[!is.na(CombinedT2$Signficant),]

CombinedT2$Measure <- factor(CombinedT2$Measure,levels=c('Treatment Differences','Standard Deviation','t Ratio','Probability>t'))
ggplot(CombinedT2, aes(Northing,Value)) + 
geom_point(aes(color=Signficant)) + #cbPalette[1]) + 
scale_colour_manual(values=cbPalette) +
labs(x="Northing", title = "Functional Statistics") + facet_wrap(~ Measure,nrow = 4,scales="free_y") + xlim(650,1400)
```

# Discussion
## Summarizing Results
Presentation of experimental results in functional form as an appeal. Consider how a farmer might experience crop yields - in a harvester, moving through time and space. Yield changes may be detectable by changes in engine speed or output; a farmer may remember patches of different soil types experienced during planting. 

This method is not suitable for all executions of on-farm strip trials. In this example, the length of each strip is large, compared to the distance across strips. Thus, we can capture a degree of information about spatial yield variability along the length of strips and minimize the variance between strips, relative to length. A field with many short strips may not be as amenable to this type of analysis, and if the strips are short enough, methods associated with small-plot analysis may be preferred.

This method may also be problematic when the strips are not all of the same length or there are gaps in the strips, as shown in Example 2. The number of replicates is not a constant function of distance, so there will be jumps in the functional form of the $t$-test; this is a less visually appealing presentation and may make interpretation difficult.

Finally, the examples presented here were not truly randomized within blocks; each pair of strips has the same treatment structure. It would be desirable to assign treatments at random among pairs of strips, but that presents extra effort in the execution of the strip trial, and may be impossible as in the case of a split-planter trial. The lack of randomization among units may introduce a bias in the analysis. Indeed, in the first example there is a definite yield trend from north to south that may have resulted in larger than expected yield differences among the two varieties. Spatial methods can be used to model variation in two dimensions and can provide a more accurate assessment 

# Interpretation of p-values



# Tables

Strip | Variety | Yield Data Points | Yield Average | Sample SD | Sample SE | Northing
------|---------|-------------------|---------------|-----------|-----------|----------
1     |       E | 518 | 162.8279 | 29.83083 | 0.2399760 | 3.787845
2     |       B | 527 | 175.5724 | 39.67935 | 0.2743955 | 16.082465
3     |       E | 519 | 163.8603 | 32.22227 | 0.2491692 | 28.274649
4     |       B | 526 | 188.5818 | 30.38731 | 0.2403551 | 40.354902
5     |       E | 530 | 175.2685 | 27.12060 | 0.2262099 | 52.571117
6     |       B | 528 | 192.4624 | 24.31691 | 0.2146037 | 64.626749
7     |       E | 535 | 185.2256 | 23.45168 | 0.2093679 | 76.832520
8     |       B | 530 | 197.2943 | 23.57872 | 0.2109221 | 89.062328
9     |       E | 529 | 181.0466 | 26.00689 | 0.2217259 | 101.170738
10    |       B | 542 | 191.6723 | 24.83957 | 0.2140782 | 113.383573
11    |       E | 551 | 193.0240 | 25.16112 | 0.2136924 | 125.521797
12    |       B | 534 | 208.5366 | 20.67455 | 0.1967648 | 137.705798
      |  |  | Treatment Mean | SD |  | 
      | E |  | 192.3533 | 11.97669 |  | 
      | B |  | 176.8755 | 10.79454 |  | 
      | Difference |  |  | 11.38561 |  | 
      
      
Formula      | Univariate | Functional 
-------------|---------------------------|--------------
Means model  |  $y_{ij} = \mu_i + e_{ij}$ | $y_{ij}(d) = \mu_i(d) + e_{ij}(d)$       	
Mean estimate	|  $\widehat{\mu}_i = \frac{\sum_{j=1}^{N_i} y_{ij}}{N_i}$ |$\widehat{\mu}_i(d) = \frac{\sum_{j=1}^{N_i} y_{ij}(d)}{N_i}$
Variance estimate	|  $\widehat{\sigma}^2 = \frac{\sum_{j=1}^{N} (y_{ij}-\widehat{\mu}_i)^2}{N - k}$ | $\widehat{\sigma}^2(d) = \frac{\sum_{j=1}^{N(d)} (y_{ij}(d)-\widehat{\mu}_i(d))^2}{N(d) - k(d)}$
Difference between means		|  $\widehat{\delta} = \widehat{\mu}_i-\widehat{\mu}_j$ | $\widehat{\delta}(d) = \widehat{\mu}_i(d)-\widehat{\mu}_j(d)$
Test statistic 	|  $t = \frac{\widehat{\delta}}{\sqrt{2 \widehat{\sigma}^2 / n}}$ | $t = \frac{\widehat{\delta(d)}}{\sqrt{2 \widehat{\sigma}^2(d) / n(d)}}$
		
<!-- Required replicates	 -->
<!-- Detectable differences	 -->
      
# References
