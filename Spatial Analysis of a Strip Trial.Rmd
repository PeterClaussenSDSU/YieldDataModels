---
title: "Spatial Analysis of a Strip Trial"
author: "Peter Claussen"
date: "11/10/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
models=12
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(gridExtra)
library(mgcv)
library(splines)
grey <- "#999999"
orange <- "#E69F00"
skyblue <- "#56B4E9"
bluishgreen <- "#009E73"
yellow <- "#F0E442"
blue <- "#0072B2"
vermillion <- "#D55E00"
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#0072B2", "#D55E00", "#F0E442","#CC79A7","#000000","#734f80", "#2b5a74", "#004f39", "#787221", "#003959", "#6aaf00", "#663cd3")
```

```{r, include=FALSE}
source('./R/remove.harvest.outliers.fn.R')
source('./R/spatial.model.selection.R')
source('./R/select.best.variogram.R')
source('./R/spatial.selection.plots.R')
source('./R/read.yield.data.R')
source('./R/combined.map.R')
```


# Introduction

With the advent of crop harvesters equipped with yield monitors and GPS enabled sensors, there has been a rapid increase in on-farm product trials. These trial are usually conducted in strips; farmers are asked to apply a test product to a small portion of their fields in a number of strips, leaving the remainder of the field untreated. The treated strips can then be compared to the untreated portions of the field to evaluate the effectiveness of the product under real-world conditions, and to engage farmers in product testing.

However, less attention has been payed to the development of methods to analysis the results of on-farm strip trials. In some cases, the strips are analyzed as if they were single plots in a small-plot trial, such as a standard randomized complete block design. Such analysis is undesirable for several reasons, two of the chief reasons being a lack of randomization of the treatments to strips and the lack of exchangibility among the strips.

Other analysis have been proposed. Here, we develop a geospatial based model to assess the effect of treatment on strips of product.

## The Spatial Model

We consider a spatial model for a strip trial of the form

$$
Z(\mathbf{s_i}) = \theta(\mathbf{s}_i) + Y(\mathbf{s}_i) + e(\mathbf{s}_i)
$$

The spatial model consists of three components. The first is the fixed effect component and includes the experimental treatments applied to point $\mathbf{s_i}$. The inherent response or fertility, in the absence of treatment, is represented as a random spatial field $Y$  that can be index by points $\mathbf{s}_i$. Finally, there is a white-noise error process $e$ associated with measurement of the realized random field, also indexed by $\mathbf{s}_i$.

## Selecting a form for the random spatial field $Y$

$Y(\mathbf{s_i})$ usually does not take a known, closed form formula. Instead, the specific realization of random spatial field is approximated using a series of low-order polynomials. In this section, we compare basis splines smoothers found using the R `lm` function and comparable splines in generalized additive models using the R library `mgcv`, specifically with the `gam` function.

###  Information Criteria

Information criteria, such as AIC or BIC, are commonly used to select the 'best' number of parameters in a statistical model. 

These are calculated as adding, or penalizing, some value based on the number of parameters from the log-likelihood. The formula for AIC can be simplified to

$$
AIC = - 2 \ln(\widehat{L}) + 2k
$$
where $\widehat{L}$ is the maximum value of the likelihood function for model, ($L=P(X|\theta,M)$, with $X$ being the data and $M$ the model with parameters $\theta$) and $k$ is the number of parameters in the model. Similarly, BIC is given by

$$
BIC =  - 2 \ln(\widehat{L}) + k \ln(n)
$$
with $k$ and $\widehat{L}$ as before and $n$ is the number of observations in $X$. These criteria are well defined for methods that depend on maximum likelihood estimation, but are less well suited when other optimization methods are employed, such as the penalized maximum likelihood used in GAM (generalized additive models). In this paper, we consider alternative methods for selection an optimal number of parameters for smoothing a spatial random field, specifically the semivariogram.


### The Semivariogram
 
Consider a simple random field, absent any fixed effects.
$$
Z(\mathbf{s_i}) = Y(\mathbf{s_i}) + e(\mathbf{s_i})
$$

One of the properties of a random field is the correlation structure among the various points $\mathbf{s_i}$. Specifically, the covariance function of two points $s_i$ and $s_i +h$ separated by a distance $h$ is a function strictly of the distance $h$, when the spatial field is isotropic and stationary. We write this as

$$
var(Y(\mathbf{s} + \mathbf{h}) - Y(\mathbf{s} + \mathbf{h})) = 2\gamma_Y(\mathbf{h})
$$

that is, the variance between two points $\mathbf{s}_i + \mathbf{h}$  and $\mathbf{s}_i$ is strictly a function of the distance between the points, and is not influenced by absolute position or direction.

The semivariogram usually starts at some non-zero point at the x origin (where x represesnts h, or the distance between two points). This non-zero value represents the nugget. The semivariogram usually rises along the x-axis, as the variance between points increases with distance. At some point the semivariogram become asymptotic; this upper limit is sometimes call the sill. Figure \@ref{fig:IdealSemivariogram} show an idealized semivariogram based on a spherical model.

```{r,IdealSemivariogram,,fig.cap="Idealized spherical semivariogram",echo=FALSE}
#From https://www.supergeotek.com/Spatial_Statistical_ENG_HTML/spherical_mode.htm
n=5
r=80
d=(1:100)/100
sph <- function(C0,C,h,a) {
  if(h==0) {
    return(0)
  } else if (h > a) {
    return(C0+C)
  } else {
    return(C0 + C*((3/2)*(h/a) - (1/2)*(h/a)^3))
  }
}
y = d
for(i in 1:length(d)) {
  y[i]=sph(1,1,d[i],0.5)
}
 plot(d,y,ylim=c(0,2),type='l',ylab='Semivariance',xlab='Distance',main="Idealized Spherical Semivariogram")
```

We use semivariograms on both the fitted models and on the residuals of the fitted models. We consider the best fit model to produce a semivarigram that has a nugget near 0, as points not separated in space should have no covariance. We then look for the model with a nuggest not significantly different from 0, but produces the largest sill. This we take as evidence the the associated model has explained the majority of the spatial variation. Thus, we choose as the best most the most detailed model producing nugget not significantly different from 0. We call this the nugget selection.

Alternative, we consider that if a proposed spatial model adequately fits the data, then the residuals will be a white-noise process and have no spatial correlation. In this case the semivariogram will be a flat line. We test each proposed spatial most and choose the simplest model that produces a residual semivariogram that is flat; that is, the slope of a simple regression of variance versus distance is statistically not different from 0. We call this the residual method.

We compare these methods to more traditional methods of model selection, the adjusted $R^2$ and cross-validation. When fitting a model using `lm`, we use the $k$-fold cross validation method, as the preferred leave-one-out cross validation is too computationally expensive for these data; some strip trials have several thousand data points. For the GAM fit models, we use the generalized cross validation score provided as part of the model fit.

# Materials and Methods

## Example 1
```{r,echo=FALSE}
load(file="~/Work/git/ASA_CSSA_SSSA/2017/Workshop/Case Study 2/Strips.Rda")
```


```{r,EastQuarterMaps,echo=FALSE,fig.width=8,fig.height=6}
grid.arrange(
  arrangeGrob(
        ggplot(EastQuarter.dat, aes(Easting,Northing)) + 
           geom_point(aes(colour = Product),size=2) + 
           scale_colour_manual(values=cbPalette) +
           #scale_colour_manual(values=cbPalette[pair.colors]) +
           labs(colour = "Variety", x="Easting", y="Northing", title = "Seeding Map"),
    ggplot(EastQuarter.dat, aes(Easting,Northing)) + 
           geom_point(aes(colour = Yield),size=2) + 
           scale_colour_gradient2(low=vermillion, mid=yellow, high=blue, midpoint = median(EastQuarter.dat$Yield)) +
           labs(colour = "Yield", x="Easting", y="Northing",title="Harvest Map"),
    nrow=2
  )
)
```

## Example 2


```{r,echo=FALSE}
treated.2019.dat <- read.csv(file='../ManagementZoneML/data/B 2019 Soybean Treated.csv')
left = 1000
treated.2019.dat <- treated.2019.dat[treated.2019.dat$Longitude >left,]
treated.2019.dat$Pass <- treated.2019.dat$Block
treated.2019.dat$Block <- as.factor(ceiling(treated.2019.dat$Pass/2))
treated.2019.dat$Sprayed <- treated.2019.dat$Pass %in% c(2,4,6,8)
treated.2019.dat$Easting <- treated.2019.dat$Longitude
treated.2019.dat$Northing <- treated.2019.dat$Latitude
```

```{r,echo=FALSE,include = FALSE,eval=FALSE}
treated.2019.dat$SprayedRank <- rank(treated.2019.dat$Sprayed)
treated.2019.dat$SprayedRank <- treated.2019.dat$SprayedRank/max(treated.2019.dat$SprayedRank)

treated.2019.dat$YieldRank <- rank(treated.2019.dat$Yield)
treated.2019.dat$YieldRank <- treated.2019.dat$YieldRank/max(treated.2019.dat$YieldRank)

MapsSprayed <- data.frame(Longitude=c(treated.2019.dat$Longitude,
                                treated.2019.dat$Longitude),
                   Latitude=c(treated.2019.dat$Latitude,
                              treated.2019.dat$Latitude),
                   Value=c(treated.2019.dat$Sprayed,
                           treated.2019.dat$Yield),
                   Map=c(rep('Spray',length(treated.2019.dat$Sprayed)),
                         rep('Yield',length(treated.2019.dat$Yield))))

#MapsSprayed <- data.frame(Longitude=c(treated.2019.dat$Longitude,
#                                treated.2019.dat$Longitude),
#                   Latitude=c(treated.2019.dat$Latitude,
#                              treated.2019.dat$Latitude),
#                   Value=c(treated.2019.dat$SprayedRank,
#                           treated.2019.dat$YieldRank),
#                   Map=c(rep('Spray',length(treated.2019.dat$SprayedRank)),
#                         rep('Yield',length(treated.2019.dat$YieldRank))))
```

```{r,echo=FALSE, fig.width=6, fig.height=4,eval=FALSE}
ggplot(MapsSprayed, aes(Longitude,Latitude)) + 
geom_point(aes(colour = Value),size=1) + 
scale_colour_gradient2(low=vermillion, mid=yellow, high=blue, midpoint = 0.5) +
labs(colour = "Relative Rank", x="Easting", y="Northing", title = "Fungicide Strip Trial (Raw data by rank)") + facet_wrap(~ Map)
```

```{r,eval=FALSE}
grid.arrange(
  arrangeGrob(
        ggplot(treated.2019.dat, aes(Easting,Northing)) + 
           geom_point(aes(colour = Sprayed),size=2) + 
           scale_colour_manual(values=cbPalette) +
           #scale_colour_manual(values=cbPalette[pair.colors]) +
           labs(colour = "Sparyed", x="Easting", y="Northing", title = "Spray Map"),
    ggplot(treated.2019.dat, aes(Easting,Northing)) + 
           geom_point(aes(colour = Yield),size=2) + 
           scale_colour_gradient2(low=vermillion, mid=yellow, high=blue, midpoint = median(treated.2019.dat$Yield)) +
           labs(colour = "Yield", x="Easting", y="Northing",title="Harvest Map"),
    nrow=2
  )
)
```


```{r,echo=FALSE,include=FALSE}
ggplot(treated.2019.dat, aes(x=Yield)) + geom_histogram()
ggplot(treated.2019.dat, aes(sample = Yield)) + stat_qq() + stat_qq_line()
ggplot(treated.2019.dat, aes(x=Yield)) + geom_histogram()
ggplot(treated.2019.dat, aes(sample = Yield)) + stat_qq() + stat_qq_line()
```


```{r,echo=FALSE}
treated.2019.dat$SprayedRank <- rank(treated.2019.dat$Sprayed)
treated.2019.dat$SprayedRank <- treated.2019.dat$SprayedRank/max(treated.2019.dat$SprayedRank)

treated.2019.dat$YieldRank <- rank(treated.2019.dat$Yield)
treated.2019.dat$YieldRank <- treated.2019.dat$YieldRank/max(treated.2019.dat$YieldRank)

MapsSprayed <- data.frame(Longitude=c(treated.2019.dat$Longitude,
                                treated.2019.dat$Longitude),
                   Latitude=c(treated.2019.dat$Latitude,
                              treated.2019.dat$Latitude),
                   Value=c(treated.2019.dat$SprayedRank,
                           treated.2019.dat$YieldRank),
                   Map=c(rep('Spray',length(treated.2019.dat$SprayedRank)),
                         rep('Yield',length(treated.2019.dat$YieldRank))))
```

```{r,echo=FALSE, fig.width=6, fig.height=4}
ggplot(MapsSprayed, aes(Longitude,Latitude)) + 
geom_point(aes(colour = Value),size=1) + 
scale_colour_gradient2(low=vermillion, mid=yellow, high=blue, midpoint = 0.5) +
labs(colour = "Relative Rank", x="Easting", y="Northing", title = "Fungicide Strip Trial") + facet_wrap(~ Map)
```

## Algorithm

First, we select a range of $k$ values to consider. This is largely done by trial an error. We select a sufficiently large range (i.e. 40-400), then examine the variograms and adjust $k$ values to provide tighter coverage of the critical values.

```{r,echo=FALSE}
require(gstat)
require(mgcv)
require(splines)

k.vec = (1:10)*30
b.vec = (1:10)*3
models = length(k.vec)
Models1 <- vector(mode='list',length=models)
ModelsLM1 <- vector(mode='list',length=models)
```


```{r,echo=FALSE}
#We save predicted values from the various smoothers for plotting.
Predicted1 <- NULL
PredictedLM1 <- NULL
```

```{r,echo=FALSE}
#We compute variograms independently for both predicted values from the smoothers and for the residuals.
PredictedVG1 <- vector(models+1,mode='list')
ResidualsVG1 <- vector(models+1,mode='list')
PredictedVGLM1 <- vector(models+1,mode='list')
ResidualsVGLM1 <- vector(models+1,mode='list')
```

```{r,include=FALSE}
#For reference, we compute a variogram for the raw `Yield` values, and save variograms values for each level of $k$.
tmp.var <- variogram(Yield~1, 
                     locations=~Easting+Northing,
                      data=EastQuarter.dat)
  
PredictedVGData1 <-  data.frame(Distance=tmp.var$dist,
                               Gamma=tmp.var$gamma,
                               K=0)
ResidualsVGData1 <-  PredictedVGData1
PredictedVGDataLM1 <-  data.frame(Distance=tmp.var$dist,
                               Gamma=tmp.var$gamma,
                               K=0)
ResidualsVGDataLM1 <-  PredictedVGDataLM1
```  
  
  
```{r,include=FALSE}
GAM1AdjR2 <- 1:(length(k.vec)+1)
GAM1GCV <- 1:(length(k.vec)+1)

null.model <- gam(Yield ~ Product,data=EastQuarter.dat[,c('Yield','Product','Northing','Easting')])

default.model <- gam(Yield ~ Product+s(Easting,Northing), data=EastQuarter.dat[,c('Yield','Product','Northing','Easting')])

null.summary <- summary(null.model)
GAM1AdjR2[1] <- null.summary$r.sq
GAM1GCV[1] <- null.summary$sp.criterion
for(i in 1:length(k.vec)) {
  tmp.dat <- EastQuarter.dat[, c('Yield','Product','Northing','Easting')]
  fmla <- paste('Yield ~ Product + s(Easting,Northing,k=',k.vec[i],')')
  Models1[[i]] <- gam(as.formula(fmla),data=tmp.dat)
  
  gam.summary <- summary(Models1[[i]])
  GAM1AdjR2[i+1] <- gam.summary$r.sq
  GAM1GCV[i+1] <- gam.summary$sp.criterion

  tmp.dat$Yield <- predict(Models1[[i]])
  tmp.dat$K = k.vec[i]
  tmp.dat$Residuals <- residuals(Models1[[i]])
    
  Predicted1 <- rbind(Predicted1, tmp.dat)
    
  tmp.var <- variogram(Yield~1,  locations=~Easting+Northing,  data=tmp.dat)
  PredictedVG1[[i+1]] <- tmp.var

  PredictedVGData1 <- rbind(PredictedVGData1,
                         data.frame(Distance=tmp.var$dist,
                                    Gamma=tmp.var$gamma,
                                     K=k.vec[i]))
  tmp.var <- variogram(Residuals~1, locations=~Easting+Northing, data=tmp.dat)
  ResidualsVG1[[i+1]] <- tmp.var
  ResidualsVGData1 <- rbind(ResidualsVGData1,
                             data.frame(Distance=tmp.var$dist,
                                        Gamma=tmp.var$gamma,
                                        K=k.vec[i]))
}
```

```{r,include=FALSE}
LM1AdjR2 <- 1:(length(k.vec)+1)
KFoldCVLM1 <- 1:(length(k.vec)+1)

#null model has no spatial information
subdata = EastQuarter.dat[,c('Yield','Product','Northing','Easting')]
nulllm.model <- lm(Yield ~ Product,data=subdata)
current.summary <- summary(nulllm.model)
LM1AdjR2[1] <- current.summary$adj.r.squared
#compute k-fold cross validation
#ordinary LOOCV takes several hours to compute for just one set of models.
#we'll have k folds
k=10
#assign folds to data in groups of 10, at random. We do this in the order the data were collected to
#be sure that that test data set is uniformly space throughout the field
foldgroups <- ceiling(dim(subdata)[1]/k)
maxidx = dim(subdata)[1]
subdata$Fold <- 0
for(j in 1:foldgroups) {
  range = 1:10 + (j-1)*10
  if(j*10>maxidx) {
    range = ((j-1)*10):maxidx
    subdata$Fold[range] <- sample(1:length(range))
  } else {
    subdata$Fold[range] <- sample(1:10)
  }
}
#now, hold out fold and fit model to training data
sum <- 0
FoldMSE <- 1:k
for(j in 1:k) {
  current.train <- subdata[subdata$Fold != j,]
  current.test <- subdata[subdata$Fold == j,]
  current.model <- lm(Yield ~ Product, data=current.train)
  predicted <- predict(current.model, newdata = current.test)
  FoldMSE[j] <- sum(predicted - current.test$Yield)^2/dim(current.test)[1]
}
KFoldCVLM1[1] <- mean(FoldMSE)
```
```{r,,include=FALSE,echo=FALSE}
for(i in 1:length(k.vec)) {
  
  tmp.dat <- EastQuarter.dat[, c('Yield','Product','Northing','Easting')]
  
  fmla <- paste('Yield ~ Product + bs(Easting,df=',b.vec[i],')*bs(Northing,df=',b.vec[i],')')
  ModelsLM1[[i]] <- lm(as.formula(fmla), data=tmp.dat)
  #compute adjusted R2
  current.summary <- summary(ModelsLM1[[i]])
  LM1AdjR2[i+1] <- current.summary$adj.r.squared
  #use the same folds as the null model
  tmp.dat$Fold <- subdata$Fold
  sum <- 0
  FoldMSE <- 1:k
  for(j in 1:k) {
    current.train <- tmp.dat[tmp.dat$Fold != j,]
    current.test <- tmp.dat[tmp.dat$Fold == j,]
    current.model <- lm(as.formula(fmla), data=current.train)
    predicted <- predict(current.model, newdata = current.test)
    FoldMSE[j] <- sum(predicted - current.test$Yield)^2/dim(current.test)[1]
 }
  KFoldCVLM1[i+1] <- mean(FoldMSE)


  tmp.dat$Yield <- predict(ModelsLM1[[i]])
  tmp.dat$K = k.vec[i]
  tmp.dat$Residuals <- residuals(ModelsLM1[[i]])
    
  PredictedLM1 <- rbind(PredictedLM1, tmp.dat)
    
  tmp.var <- variogram(Yield~1,  locations=~Easting+Northing,  data=tmp.dat)
  PredictedVGLM1[[i+1]] <- tmp.var

  PredictedVGDataLM1 <- rbind(PredictedVGDataLM1,
                         data.frame(Distance=tmp.var$dist,
                                    Gamma=tmp.var$gamma,
                                     K=b.vec[i]))
  tmp.var <- variogram(Residuals~1, locations=~Easting+Northing, data=tmp.dat)
  ResidualsVGLM1[[i+1]] <- tmp.var
  ResidualsVGDataLM1 <- rbind(ResidualsVGDataLM1,
                             data.frame(Distance=tmp.var$dist,
                                        Gamma=tmp.var$gamma,
                                        K=b.vec[i]))
}
```

From the variograms, we fit linear models to characterize the variograms to automate selecting the 'best' variograms. For the Residual variograms, we wish to find the variogram with the slope of $\gamma$ versus $d$ nearest to zero, so we fit a linear model and select the smallest level of $k$ that produces a slope not significantly different than 0.

For the predict yield variograms, we fit a spline model, and identify the largest level of $k$ that produces nugget effect not significantly different from 0. A nugget of 0 suggests that there is no white noise in the smoothing model; if there is a nugget effect in the predicted data we may have overfit the model and introduced excess noise in out smoother.

```{r,include=FALSE}
Slopes.dat <- data.frame(K=unique(ResidualsVGData1$K))
tmp.lm <- lm(Gamma ~ Distance,data=ResidualsVGData1[ResidualsVGData1$K==0,])
Slopes.dat$Intercept <- coef(tmp.lm)[1]
Slopes.dat$Slope <- coef(tmp.lm)[2]
sum <- summary(tmp.lm)
Slopes.dat$T <- sum$coefficients['Distance','t value']
Slopes.dat$P <- sum$coefficients['Distance','Pr(>|t|)']
  
tmp.lm <- lm(Gamma ~ bs(Distance),data=PredictedVGData1[PredictedVGData1$K==0,])
Slopes.dat$Nugget <- coef(tmp.lm)[1]
  
  for (k in 1:length(Slopes.dat$K)) {
    K <- Slopes.dat$K[k]
    tmp.lm <- lm(Gamma ~ Distance,data=ResidualsVGData1[ResidualsVGData1$K==K,])
    Slopes.dat$Intercept[k] <- coef(tmp.lm)[1]
    Slopes.dat$Slope[k] <- coef(tmp.lm)[2]
    sum <- summary(tmp.lm)
    Slopes.dat$T[k] <- sum$coefficients['Distance','t value']
    Slopes.dat$P[k] <- sum$coefficients['Distance','Pr(>|t|)']
    tmp.lm <- lm(Gamma ~ bs(Distance),data=PredictedVGData1[PredictedVGData1$K==K,])
    Slopes.dat$Nugget[k] <- coef(tmp.lm)[1]
    sum <- summary(tmp.lm)
    Slopes.dat$NuggetT[k] <- sum$coefficients[1,'t value']
    Slopes.dat$NuggetP[k] <- sum$coefficients[1,'Pr(>|t|)']
  }
  
  SelectionGAM1 <- data.frame(K = rep(c(0,k.vec),4),
                           #Criteria = as.factor(c(rep('AIC',models+1),
                           #                        rep('BIC',models+1),
                            Criteria = as.factor(c(rep('Adjusted R Squared',models+1),
                                                   rep('Generalized Cross Validation',models+1),
                                                   rep('Nugget',models+1),
                                                   rep('Slope',models+1))),
                            #Score = c(c(AIC(null.model),unlist(lapply(Models1,AIC))),
                            #          c(BIC(null.model),unlist(lapply(Models1,BIC))),
                            Score = c(GAM1AdjR2,
                                      GAM1GCV,
                                      Slopes.dat$NuggetP,
                                      Slopes.dat$P)
                            )
#SelectionGAM  
```

```{r,include=FALSE}
Slopes.dat <- data.frame(K=unique(ResidualsVGDataLM1$K))
tmp.lm <- lm(Gamma ~ Distance,data=ResidualsVGDataLM1[ResidualsVGData1$K==0,])
Slopes.dat$Intercept <- coef(tmp.lm)[1]
Slopes.dat$Slope <- coef(tmp.lm)[2]
sum <- summary(tmp.lm)
Slopes.dat$T <- sum$coefficients['Distance','t value']
Slopes.dat$P <- sum$coefficients['Distance','Pr(>|t|)']
  
tmp.lm <- lm(Gamma ~ bs(Distance),data=PredictedVGDataLM1[PredictedVGDataLM1$K==0,])
Slopes.dat$Nugget <- coef(tmp.lm)[1]
  
  for (k in 1:length(Slopes.dat$K)) {
    K <- Slopes.dat$K[k]
    tmp.lm <- lm(Gamma ~ Distance,data=ResidualsVGDataLM1[ResidualsVGDataLM1$K==K,])
    Slopes.dat$Intercept[k] <- coef(tmp.lm)[1]
    Slopes.dat$Slope[k] <- coef(tmp.lm)[2]
    sum <- summary(tmp.lm)
    Slopes.dat$T[k] <- sum$coefficients['Distance','t value']
    Slopes.dat$P[k] <- sum$coefficients['Distance','Pr(>|t|)']
    tmp.lm <- lm(Gamma ~ bs(Distance),data=PredictedVGDataLM1[PredictedVGDataLM1$K==K,])
    Slopes.dat$Nugget[k] <- coef(tmp.lm)[1]
    sum <- summary(tmp.lm)
    Slopes.dat$NuggetT[k] <- sum$coefficients[1,'t value']
    Slopes.dat$NuggetP[k] <- sum$coefficients[1,'Pr(>|t|)']
  }
  
  SelectionLM1 <- data.frame(K = rep(c(0,b.vec),4),
                            #Criteria = as.factor(c(rep('AIC',models+1),
                            #                       rep('BIC',models+1),
                            Criteria = as.factor(c(rep('Adjusted R Squared',models+1),
                                                   rep('K-Fold Cross Validation',models+1),
                                                   rep('Nugget',models+1),
                                                   rep('Slope',models+1))),
                            #Score = c(c(AIC(nulllm.model),unlist(lapply(ModelsLM1,AIC))),
                             #         c(BIC(nulllm.model),unlist(lapply(ModelsLM1,BIC))),
                            Score = c(LM1AdjR2,
                                      KFoldCVLM1,
                                      Slopes.dat$NuggetP,
                                      Slopes.dat$P)
                            )
#SelectionGAM  
```

## Example 2

```{r,include=FALSE}
k.vec2 = (1:10)*30
models = length(k.vec2)
b.vec = (1:10)*3

Models2 <- vector(mode='list',length=models)
ModelsLM2 <- vector(mode='list',length=models)

Predicted2 <- NULL

PredictedVG2 <- vector(models+1,mode='list')
ResidualsVG2 <- vector(models+1,mode='list')

tmp.var <- variogram(Yield~1, 
                     locations=~Easting+Northing,
                      data=treated.2019.dat)
  
PredictedVGData2 <-  data.frame(Distance=tmp.var$dist,
                               Gamma=tmp.var$gamma,
                               K=0)
ResidualsVGData2 <-  PredictedVGData2

null.model2 <- gam(Yield ~ Sprayed,data=treated.2019.dat[,c('Yield','Sprayed','Northing','Easting')])
default.model2 <- gam(Yield ~ Sprayed+s(Easting,Northing), data=treated.2019.dat[,c('Yield','Sprayed','Northing','Easting')])
for(i in 1:length(k.vec)) {
  tmp.dat <- treated.2019.dat[, c('Yield','Sprayed','Northing','Easting')]
  fmla <- paste('Yield ~ Sprayed + s(Easting,Northing,k=',k.vec[i],')')
  Models2[[i]] <- gam(as.formula(fmla),data=tmp.dat)
  
  fmla <- paste('Yield ~ Sprayed + bs(Easting,df=',b.vec[i],')*bs(Northing,df=',b.vec[i],')')
  ModelsLM2[[i]] <- lm(as.formula(fmla), data=tmp.dat)
  
  tmp.dat$Yield <- predict(Models2[[i]])
  tmp.dat$K = k.vec[i]
  tmp.dat$Residuals <- residuals(Models2[[i]])
    
  Predicted2 <- rbind(Predicted2, tmp.dat)
    
  tmp.var <- variogram(Yield~1,  locations=~Easting+Northing,  data=tmp.dat)
  PredictedVG2[[i+1]] <- tmp.var

  PredictedVGData2 <- rbind(PredictedVGData2,
                         data.frame(Distance=tmp.var$dist,
                                    Gamma=tmp.var$gamma,
                                     K=k.vec[i]))
  tmp.var <- variogram(Residuals~1, locations=~Easting+Northing, data=tmp.dat)
  ResidualsVG2[[i+1]] <- tmp.var
  ResidualsVGData2 <- rbind(ResidualsVGData2,
                             data.frame(Distance=tmp.var$dist,
                                        Gamma=tmp.var$gamma,
                                        K=k.vec[i]))
}

Slopes.dat2 <- data.frame(K=unique(ResidualsVGData2$K))
tmp.lm <- lm(Gamma ~ Distance,data=ResidualsVGData2[ResidualsVGData2$K==0,])
Slopes.dat2$Intercept <- coef(tmp.lm)[1]
Slopes.dat2$Slope <- coef(tmp.lm)[2]
sum <- summary(tmp.lm)
Slopes.dat2$T <- sum$coefficients['Distance','t value']
Slopes.dat2$P <- sum$coefficients['Distance','Pr(>|t|)']
  
tmp.lm <- lm(Gamma ~ bs(Distance),data=PredictedVGData2[PredictedVGData2$K==0,])
Slopes.dat2$Nugget <- coef(tmp.lm)[1]
  
  for (k in 1:length(Slopes.dat2$K)) {
    K <- Slopes.dat2$K[k]
    tmp.lm <- lm(Gamma ~ Distance,data=ResidualsVGData2[ResidualsVGData2$K==K,])
    Slopes.dat2$Intercept[k] <- coef(tmp.lm)[1]
    Slopes.dat2$Slope[k] <- coef(tmp.lm)[2]
    sum <- summary(tmp.lm)
    Slopes.dat2$T[k] <- sum$coefficients['Distance','t value']
    Slopes.dat2$P[k] <- sum$coefficients['Distance','Pr(>|t|)']
    tmp.lm <- lm(Gamma ~ bs(Distance),data=PredictedVGData2[PredictedVGData2$K==K,])
    Slopes.dat2$Nugget[k] <- coef(tmp.lm)[1]
    sum <- summary(tmp.lm)
    Slopes.dat2$NuggetT[k] <- sum$coefficients[1,'t value']
    Slopes.dat2$NuggetP[k] <- sum$coefficients[1,'Pr(>|t|)']
  }
  
  SelectionGAM2 <- data.frame(K = rep(c(0,k.vec),4),
                            Criteria = as.factor(c(rep('AIC',models+1),
                                                   rep('BIC',models+1),
                                                   rep('Nugget',models+1),
                                                   rep('Slope',models+1))),
                            Score = c(c(AIC(null.model2),unlist(lapply(Models2,AIC))),
                                      c(BIC(null.model2),unlist(lapply(Models2,BIC))),
                                      Slopes.dat2$NuggetP,
                                      Slopes.dat2$P)
                            )
```


```{r,include=FALSE}
k.vec2 = (1:10)*30
models = length(k.vec2)
b.vec = (1:10)*3

ModelsLM2 <- vector(mode='list',length=models)

PredictedLM2 <- NULL

PredictedVGLM2 <- vector(models+1,mode='list')
ResidualsVGLM2 <- vector(models+1,mode='list')

tmp.var <- variogram(Yield~1, 
                     locations=~Easting+Northing,
                      data=treated.2019.dat)
  
PredictedVGDataLM2 <-  data.frame(Distance=tmp.var$dist,
                               Gamma=tmp.var$gamma,
                               K=0)
ResidualsVGDataLM2 <-  PredictedVGDataLM2

nulllm.model2 <- lm(Yield ~ Sprayed,data=treated.2019.dat[,c('Yield','Sprayed','Northing','Easting')])
for(i in 1:length(k.vec)) {
  tmp.dat <- treated.2019.dat[, c('Yield','Sprayed','Northing','Easting')]
  
  fmla <- paste('Yield ~ Sprayed + bs(Easting,df=',b.vec[i],')*bs(Northing,df=',b.vec[i],')')
  ModelsLM2[[i]] <- lm(as.formula(fmla), data=tmp.dat)
  
  tmp.dat$Yield <- predict(ModelsLM2[[i]])
  tmp.dat$K = k.vec[i]
  tmp.dat$Residuals <- residuals(ModelsLM2[[i]])
    
  PredictedLM2 <- rbind(Predicted2, tmp.dat)
    
  tmp.var <- variogram(Yield~1,  locations=~Easting+Northing,  data=tmp.dat)
  PredictedVGLM2[[i+1]] <- tmp.var

  PredictedVGDataLM2 <- rbind(PredictedVGDataLM2,
                         data.frame(Distance=tmp.var$dist,
                                    Gamma=tmp.var$gamma,
                                     K=b.vec[i]))
  tmp.var <- variogram(Residuals~1, locations=~Easting+Northing, data=tmp.dat)
  ResidualsVGLM2[[i+1]] <- tmp.var
  ResidualsVGDataLM2 <- rbind(ResidualsVGDataLM2,
                             data.frame(Distance=tmp.var$dist,
                                        Gamma=tmp.var$gamma,
                                        K=b.vec[i]))
}

Slopes.dat2 <- data.frame(K=unique(ResidualsVGDataLM2$K))
tmp.lm <- lm(Gamma ~ Distance,data=ResidualsVGDataLM2[ResidualsVGDataLM2$K==0,])
Slopes.dat2$Intercept <- coef(tmp.lm)[1]
Slopes.dat2$Slope <- coef(tmp.lm)[2]
sum <- summary(tmp.lm)
Slopes.dat2$T <- sum$coefficients['Distance','t value']
Slopes.dat2$P <- sum$coefficients['Distance','Pr(>|t|)']
  
tmp.lm <- lm(Gamma ~ bs(Distance),data=PredictedVGDataLM2[PredictedVGDataLM2$K==0,])
Slopes.dat2$Nugget <- coef(tmp.lm)[1]
  
  for (k in 1:length(Slopes.dat2$K)) {
    K <- Slopes.dat2$K[k]
    tmp.lm <- lm(Gamma ~ Distance,data=ResidualsVGDataLM2[ResidualsVGDataLM2$K==K,])
    Slopes.dat2$Intercept[k] <- coef(tmp.lm)[1]
    Slopes.dat2$Slope[k] <- coef(tmp.lm)[2]
    sum <- summary(tmp.lm)
    Slopes.dat2$T[k] <- sum$coefficients['Distance','t value']
    Slopes.dat2$P[k] <- sum$coefficients['Distance','Pr(>|t|)']
    tmp.lm <- lm(Gamma ~ bs(Distance),data=PredictedVGDataLM2[PredictedVGDataLM2$K==K,])
    Slopes.dat2$Nugget[k] <- coef(tmp.lm)[1]
    sum <- summary(tmp.lm)
    Slopes.dat2$NuggetT[k] <- sum$coefficients[1,'t value']
    Slopes.dat2$NuggetP[k] <- sum$coefficients[1,'Pr(>|t|)']
  }
  
  SelectionLM2 <- data.frame(K = rep(c(0,b.vec),4),
                            Criteria = as.factor(c(rep('AIC',models+1),
                                                   rep('BIC',models+1),
                                                   rep('Nugget',models+1),
                                                   rep('Slope',models+1))),
                            Score = c(c(AIC(nulllm.model2),unlist(lapply(ModelsLM2,AIC))),
                                      c(BIC(nulllm.model2),unlist(lapply(ModelsLM2,BIC))),
                                      Slopes.dat2$NuggetP,
                                      Slopes.dat2$P)
                            )
```

# Results

## Example 1

```{r,SelectionLM1, fig.cap="Selection criteria for linear regression fit basis splines models",echo=FALSE}
ggplot(SelectionLM1, aes(K,Score)) + 
    geom_point(aes(colour = Criteria),size=2) + 
    geom_line(aes(colour = Criteria),size=1) + 
    scale_colour_manual(values=cbPalette) + facet_wrap(~Criteria,nrow=3,scales="free_y") +
    labs(title="Scores for LM smoothers", x ="Smoothing Parameter", y = "Score")
```

```{r,SelectionGAM1, fig.cap="Selection criteria for GAM fit basis splines models",echo=FALSE}
ggplot(SelectionGAM1, aes(K,Score)) + 
    geom_point(aes(colour = Criteria),size=2) + 
    geom_line(aes(colour = Criteria),size=1) + 
    scale_colour_manual(values=cbPalette) + facet_wrap(~Criteria,nrow=3,scales="free_y") +
    labs(title="Scores for GAM smoothers", x ="Smoothing Parameter", y = "Score")
```



```{r,include=FALSE,echo=FALSE}
summary(null.model)
summary(default.model)
summary(Models1[[8]])
summary(Models1[[9]])
```

```{r,include=FALSE,echo=FALSE}
gam.check(default.model)
gam.check(Models1[[8]])
gam.check(Models1[[9]])
```


```{r,VariogramsGAM1, fig.cap="Variograms for GAM basis spline models fit to data from Example 1", echo=FALSE}
PredictedVGData1$Source <- "Smoothed Yield"
ResidualsVGData1$Source <- "Residuals"
side.dat <- rbind(PredictedVGData1,ResidualsVGData1)
side.dat$K <- factor(side.dat$K)

ggplot(side.dat, aes(Distance,Gamma)) + 
    geom_point(aes(colour = K),size=2) + 
    geom_smooth(aes(group = K,color=K), se=FALSE,alpha=0.5) +
    scale_colour_manual(values=c(cbPalette,cbPalette)) + 
    labs(title=paste('Variograms, GAM, Model 1'), x ="Distance (m)", y = "Covariance") +
    facet_wrap(~ Source, scales = "free")
```

```{r,VariogramsLM1, fig.cap="Variograms for linear regression basis spline models fit to data from Example 1",}
PredictedVGDataLM1$Source <- "Smoothed Yield"
ResidualsVGDataLM1$Source <- "Residuals"
side.dat <- rbind(PredictedVGDataLM1,ResidualsVGDataLM1)
side.dat$K <- factor(side.dat$K)

ggplot(side.dat, aes(Distance,Gamma)) + 
    geom_point(aes(colour = K),size=2) + 
    geom_smooth(aes(group = K,color=K), se=FALSE,alpha=0.5) +
    scale_colour_manual(values=c(cbPalette,cbPalette)) + 
    labs(title=paste('Variograms, LM, Example 1'), x ="Distance (m)", y = "Covariance") +
    facet_wrap(~ Source, scales = "free")
```

## Example 2

```{r,ModelSelectionGAM2, fig.cap="Model selection criteria for GAM basis spline models fit to data from example 2", echo=FALSE}
ggplot(SelectionGAM2, aes(K,Score)) + 
    geom_point(aes(colour = Criteria),size=2) + 
    geom_line(aes(colour = Criteria),size=1) + 
    scale_colour_manual(values=cbPalette) + facet_wrap(~Criteria,nrow=3,scales="free_y") +
    labs(title="Scores for GAM smoothers", x ="Smoothing Parameter", y = "Score")
```

```{r,ModelSelectionLM2, fig.cap="Model selection criteria for GAM basis spline models fit to data from example 2", echo=FALSE}
ggplot(SelectionLM2, aes(K,Score)) + 
    geom_point(aes(colour = Criteria),size=2) + 
    geom_line(aes(colour = Criteria),size=1) + 
    scale_colour_manual(values=cbPalette) + facet_wrap(~Criteria,nrow=3,scales="free_y") +
    labs(title="Scores for GAM smoothers", x ="Smoothing Parameter", y = "Score")
```

```{r,eval=FALSE}
summary(null.model2)
summary(default.model2)
summary(Models2[[6]])
summary(Models2[[7]])
```

```{r,eval=FALSE}
gam.check(default.model2)
gam.check(Models2[[6]])
gam.check(Models2[[7]])
```

```{r,VariogramsGAM2, fig.cap="Variograms for GAM basis spline models fit to data from Example 2", echo=FALSE}
PredictedVGData2$Source <- "Smoothed Yield"
ResidualsVGData2$Source <- "Residuals"
side.dat <- rbind(PredictedVGData2,ResidualsVGData2)
side.dat$K <- factor(side.dat$K)

ggplot(side.dat, aes(Distance,Gamma)) + 
    geom_point(aes(colour = K),size=2) + 
    geom_smooth(aes(group = K,color=K), se=FALSE,alpha=0.5) +
    scale_colour_manual(values=c(cbPalette,cbPalette)) + 
    labs(title=paste('Variograms, GAM, Example 2'), x ="Distance (m)", y = "Covariance") +
    facet_wrap(~ Source)
```

```{r,VariogramsLM2, fig.cap="Variograms for linear regression basis spline models fit to data from Example 2", echo=FALSE}
PredictedVGDataLM2$Source <- "Smoothed Yield"
ResidualsVGDataLM2$Source <- "Residuals"
side.dat <- rbind(PredictedVGDataLM2,ResidualsVGDataLM2)
side.dat$K <- factor(side.dat$K)

ggplot(side.dat, aes(Distance,Gamma)) + 
    geom_point(aes(colour = K),size=2) + 
    geom_smooth(aes(group = K,color=K), se=FALSE,alpha=0.5) +
    scale_colour_manual(values=c(cbPalette,cbPalette)) + 
    labs(title=paste('Variograms, LM, Example 2'), x ="Distance (m)", y = "Covariance") +
    facet_wrap(~ Source)
```

```{r}
Coef = c()
Source = c()
K = c()

for(i in 1:length(k.vec)) {
  coefs <- coef(Models1[[i]])
  Coef <- c(Coef,coefs[2])
  Source <- c(Source, "GAM")
  K <- c(K,k.vec[i])
  
  coefs <- coef(ModelsLM1[[i]])
  Coef <- c(Coef,coefs[2])
  Source <- c(Source, "LM")
  K <- c(K,b.vec[i])
}
```

```{r}
Plot1 <- data.frame(Coef=Coef,Source=Source,K=K)
ggplot(Plot1, aes(K,Coef)) + 
    geom_point(aes(colour = Source),size=2) + 
    geom_line(aes(colour = Source),size=1) + 
    scale_colour_manual(values=cbPalette) + #facet_wrap(~Criteria,nrow=3,scales="free_y") +
    labs(title="Coefficients, Example 1", x ="Smoothing Parameter", y = "Product Effect Estimate") + facet_wrap(~Source,scales="free_x")
```

```{r}
Coef = c()
Source = c()
K = c()

for(i in 1:length(k.vec)) {
  coefs <- coef(Models2[[i]])
  Coef <- c(Coef,coefs[2])
  Source <- c(Source, "GAM")
  K <- c(K,k.vec[i])
  
  coefs <- coef(ModelsLM2[[i]])
  Coef <- c(Coef,coefs[2])
  Source <- c(Source, "LM")
  K <- c(K,b.vec[i])
}
```

```{r}
Plot2 <- data.frame(Coef=Coef,Source=Source,K=K)
ggplot(Plot2, aes(K,Coef)) + 
    geom_point(aes(colour = Source),size=2) + 
    geom_line(aes(colour = Source),size=1) + 
    scale_colour_manual(values=cbPalette) + #facet_wrap(~Criteria,nrow=3,scales="free_y") +
    labs(title="Coefficients, Example 2", x ="Smoothing Parameter", y = "Spray Effect Estimate") + facet_wrap(~Source, scales="free_x")
```

# MCMC/Bayesian Methods

## Stan models

```{r,eval=FALSE}
library(brms)
if(!file.exists('Stan.Rda')) {
  fit.brms <- brm(Yield ~ Sprayed + s(Longitude,Latitude),data=treated.2019.dat)
  save(fit.brms,file='Stan.Rda')
  brms65 <- brm(Yield ~ Sprayed + s(Longitude,Latitude,k=65),data=treated.2019.dat)
  save(fit.brms,brms65,file='Stan.Rda')
  brms116 <- brm(Yield ~ Sprayed + s(Longitude,Latitude,k=116),data=treated.2019.dat)
  save(fit.brms,brms65,brms116,file='Stan.Rda')
  brms320 <- brm(Yield ~ Sprayed + s(Longitude,Latitude,k=320),data=treated.2019.dat)
  save(fit.brms,brms65,brms116,brms320,file='Stan.Rda')
} else {
  load(file='Stan.Rda')
}

summary(fit.brms)
#plot(fit.brms)

summary(brms65)
#plot(brms100)

summary(brms116)

summary(brms320)
#plot(brms320)
```

```{r,eval=FALSE}
library(spatialfusion)
## example based on simulated data
dat <- fusionSimulate(n.point = 20, n.area = 10, n.grid = 2, psill = 1, phi = 1, nugget = 0, tau.sq = 0.5,
point.beta = list(rbind(1,5)), area.beta = list(rbind(-1, 0.5)), distributions = c("normal","poisson"), design.mat = matrix(c(1,1,1)))
geo_data <- data.frame(x = dat$mrf[dat$sample.ind, "x"], y = dat$mrf[dat$sample.ind, "y"], cov.point = dat$data$X_point[,2],
outcome = dat$data$Y_point[[1]]) lattice_data <- sp::SpatialPolygonsDataFrame(dat$poly,
data.frame(outcome = dat$data$Y_area[[1]], cov.area = dat$data$X_area[,2]))
dat_stan <- fusionData(geo.data = geo_data, geo.formula = outcome ~ cov.point, lattice.data = lattice_data, lattice.formula = outcome ~ cov.area,
pp.data = dat$data$lgcp.coords[[1]], distributions = c("normal","poisson"), method = "Stan")
mod_stan <- fusion(data = dat_stan, n.latent = 1, bans = 0, pp.offset = 1,
prior.phi = list(distr = "normal", pars = c(1, 10))) summary(mod_stan)
```

piepho-11-2011
souza-2016


